{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C2MW24Zn7CJ1"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "noECWIvX7CJ3"
   },
   "outputs": [],
   "source": [
    "dial_train_path = 'dial_train.parquet'\n",
    "target_train_path = 'train_target.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zeVPC2g27CJ4"
   },
   "outputs": [],
   "source": [
    "target_train = pd.read_parquet(target_train_path)\n",
    "target_train.mon = pd.to_datetime(target_train.mon)\n",
    "\n",
    "dial_train = pd.read_parquet(dial_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>event_time</th>\n",
       "      <th>embedding</th>\n",
       "      <th>mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b27b9c54e72728e7bbfbe96ef2f3d49c14c9c5f0900033...</td>\n",
       "      <td>2022-01-12 12:22:28.151649</td>\n",
       "      <td>[0.34171295, -0.052265663, 0.5509638, -0.25280...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bff7260208097c052cea083ddc9e961a8d23c1b1c2b268...</td>\n",
       "      <td>2022-01-15 10:19:36.296643</td>\n",
       "      <td>[0.25192896, -0.057982136, 0.56129426, -0.2468...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c977ed2889aacd9aa35420cce5652274b1a1d347648d80...</td>\n",
       "      <td>2022-01-20 11:56:28.229993</td>\n",
       "      <td>[0.10494808, 0.12875096, 0.34333166, 0.1237644...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d2e003fda662d4362aed928dea8bdaffaaac002e6cc435...</td>\n",
       "      <td>2022-01-08 09:54:14.315763</td>\n",
       "      <td>[0.34184495, -0.0066548246, 0.41655463, -0.361...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d887ecc28f596b1ccf4d9758c1974d2c3058041082ed6a...</td>\n",
       "      <td>2022-01-11 06:19:57.134893</td>\n",
       "      <td>[0.20899382, -0.20362832, 0.50806755, -0.37998...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206238</th>\n",
       "      <td>3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...</td>\n",
       "      <td>2022-09-23 18:31:02.682112</td>\n",
       "      <td>[0.3919262, -0.042448077, 0.5407961, -0.203592...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206239</th>\n",
       "      <td>3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...</td>\n",
       "      <td>2022-09-18 11:01:40.032310</td>\n",
       "      <td>[0.49427247, -0.37785238, 0.48056543, -0.49872...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206240</th>\n",
       "      <td>3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...</td>\n",
       "      <td>2022-09-12 14:08:59.343379</td>\n",
       "      <td>[0.0058998824, -0.16908917, 0.3124224, -0.1694...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206241</th>\n",
       "      <td>3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...</td>\n",
       "      <td>2022-09-15 08:29:21.048320</td>\n",
       "      <td>[0.28633767, 0.039378952, 0.4970856, -0.255222...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206242</th>\n",
       "      <td>43a09529ef435e463414a37ef794fdea0e9f2b12b9c1ac...</td>\n",
       "      <td>2022-09-28 09:57:31.696529</td>\n",
       "      <td>[0.31883624, -0.003990489, 0.47808573, -0.3462...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206243 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id  \\\n",
       "0       b27b9c54e72728e7bbfbe96ef2f3d49c14c9c5f0900033...   \n",
       "1       bff7260208097c052cea083ddc9e961a8d23c1b1c2b268...   \n",
       "2       c977ed2889aacd9aa35420cce5652274b1a1d347648d80...   \n",
       "3       d2e003fda662d4362aed928dea8bdaffaaac002e6cc435...   \n",
       "4       d887ecc28f596b1ccf4d9758c1974d2c3058041082ed6a...   \n",
       "...                                                   ...   \n",
       "206238  3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...   \n",
       "206239  3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...   \n",
       "206240  3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...   \n",
       "206241  3b28346c9687dc7b7f293f9a232b3372fa0564cacf520b...   \n",
       "206242  43a09529ef435e463414a37ef794fdea0e9f2b12b9c1ac...   \n",
       "\n",
       "                       event_time  \\\n",
       "0      2022-01-12 12:22:28.151649   \n",
       "1      2022-01-15 10:19:36.296643   \n",
       "2      2022-01-20 11:56:28.229993   \n",
       "3      2022-01-08 09:54:14.315763   \n",
       "4      2022-01-11 06:19:57.134893   \n",
       "...                           ...   \n",
       "206238 2022-09-23 18:31:02.682112   \n",
       "206239 2022-09-18 11:01:40.032310   \n",
       "206240 2022-09-12 14:08:59.343379   \n",
       "206241 2022-09-15 08:29:21.048320   \n",
       "206242 2022-09-28 09:57:31.696529   \n",
       "\n",
       "                                                embedding mon  \n",
       "0       [0.34171295, -0.052265663, 0.5509638, -0.25280...   1  \n",
       "1       [0.25192896, -0.057982136, 0.56129426, -0.2468...   1  \n",
       "2       [0.10494808, 0.12875096, 0.34333166, 0.1237644...   1  \n",
       "3       [0.34184495, -0.0066548246, 0.41655463, -0.361...   1  \n",
       "4       [0.20899382, -0.20362832, 0.50806755, -0.37998...   1  \n",
       "...                                                   ...  ..  \n",
       "206238  [0.3919262, -0.042448077, 0.5407961, -0.203592...   9  \n",
       "206239  [0.49427247, -0.37785238, 0.48056543, -0.49872...   9  \n",
       "206240  [0.0058998824, -0.16908917, 0.3124224, -0.1694...   9  \n",
       "206241  [0.28633767, 0.039378952, 0.4970856, -0.255222...   9  \n",
       "206242  [0.31883624, -0.003990489, 0.47808573, -0.3462...   9  \n",
       "\n",
       "[206243 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dial_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def amount_agregate(tg, trx_timeseries, geo_timeseries):\n",
    "\n",
    "    feats = []\n",
    "    for mon in tg.mon.unique():\n",
    "        trx = trx_timeseries[trx_timeseries.event_time < mon]\n",
    "        geo = geo_timeseries[geo_timeseries.event_time < mon]\n",
    "        feats_mon = trx.groupby('client_id')[trxs].mean().reset_index()\n",
    "        feats_mon2 = geo.groupby('client_id')[hashes].mean().reset_index()\n",
    "        feats_mon['mon'] = mon\n",
    "        for hash in hashes:\n",
    "            feats_mon[hash] = feats_mon2[hash]\n",
    "        \n",
    "        feats.append(feats_mon)\n",
    "        print(mon)\n",
    "\n",
    "    feats = pd.concat(feats, axis=0)\n",
    "    return feats\n",
    "\n",
    "feats = amount_agregate(target_train, trx_train, geo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049336"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "# # labels = []\n",
    "\n",
    "# for i in range(len(target_train)):\n",
    "#     embeds = dial_train[(dial_train['client_id'] == target_train.iloc[i, 5]) \\\n",
    "#     & (dial_train['event_time'] < target_train.iloc[i, 0])]\n",
    "#     if len(embeds) > 0:\n",
    "#         sum_emb = embeds.groupby('client_id')['embedding'].sum()[0]\n",
    "#     else:\n",
    "#         sum_emb = np.zeros(len_emb)\n",
    "        \n",
    "#     embeddings.append(sum_emb)\n",
    "#     if i % 10000 == 0:\n",
    "#         print(i)\n",
    "#     # labels.append(target_train.iloc[i, 1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = target_train.client_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(ids, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, ids, dial_train, target_train):\n",
    "        self.df = target_train[target_train.client_id.isin(ids)]\n",
    "        self.dial_train = dial_train\n",
    "        self.target_train = target_train\n",
    "    \n",
    "    def get_emb(self, row):\n",
    "        embeddings = self.dial_train[(self.dial_train['client_id'] == row.client_id) \\\n",
    "        & (self.dial_train['event_time'] < row.mon)]\n",
    "        if len(embeddings) > 0:\n",
    "            sum_embedding = embeddings.groupby('client_id')['embedding'].sum()[0]\n",
    "        else:\n",
    "            sum_embedding = np.zeros(len_emb)\n",
    "                \n",
    "        labels = row[1:5]\n",
    "            \n",
    "        return labels, sum_embedding\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        labels, embeds = self.get_emb(row)\n",
    "        item = {}\n",
    "        item['summary_embeddings'] = torch.tensor(embeds)        \n",
    "        item['labels'] = torch.tensor(labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = dataset(train_ids, dial_train, target_train)\n",
    "val_dataset = dataset(val_ids, dial_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training parameters to be used for all models ##\n",
    "num_train_epochs = 5\n",
    "batch_size = 16\n",
    "learning_rate = 1.0e-5\n",
    "weight_decay = 0.01\n",
    "warmup_steps = 0\n",
    "max_seq_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoModel, AutoTokenizer, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import perf_counter\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for repeatability\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLBertModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels, hidden_states):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.hidden_states = hidden_states\n",
    "        self.classifier = nn.Linear(hidden_states, num_labels)\n",
    "        \n",
    "    \n",
    "    def forward(self, embedding):\n",
    "        logits = self.classifier(embedding)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "bert_model = VLBertModel(num_labels=4, hidden_states=768)\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)        \n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                    batch_size=32, \n",
    "                    sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31479550310f4e54871afd7ed2e39aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e211c888c413499799e29f79eea345c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/64042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]], device='cuda:0', dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38032/1407138089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mb_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38032/2467564726.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embedding)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "t_total = len(train_dataloader) * num_train_epochs\n",
    "\n",
    "optimizer = AdamW(bert_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = get_scheduler(name=\"cosine\", optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "criterion = nn.KLDivLoss() #nn.CrossEntropyLoss()\n",
    "\n",
    "bert_model.train()\n",
    "\n",
    "\n",
    "start = perf_counter()\n",
    "for epoch_num in trange(num_train_epochs, desc='Epochs'):\n",
    "    epoch_total_loss = 0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Batch'):              \n",
    "        b_labels = batch['summary_embeddings'].to(device)\n",
    "        b_inputs = batch['labels'].to(device)\n",
    "\n",
    "        bert_model.zero_grad()  \n",
    "        b_logits = bert_model(b_inputs)\n",
    "        m = nn.Sigmoid()\n",
    "        output = m(input)\n",
    "        \n",
    "        loss = criterion(b_logits, b_labels)\n",
    "\n",
    "        epoch_total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_loss = epoch_total_loss/len(train_dataloader)\n",
    "\n",
    "\n",
    "    print('epoch =', epoch_num)\n",
    "    print('    epoch_loss =', epoch_total_loss)\n",
    "    print('    avg_epoch_loss =', avg_loss)\n",
    "    print('    learning rate =', optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "end = perf_counter()\n",
    "bert_training_time = end- start\n",
    "print('Training completed in ', bert_training_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
